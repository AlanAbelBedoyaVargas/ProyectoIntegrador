import streamlit as st
from langchain_community.llms import Ollama
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

#Monitoreo con LangSmith

import os
from dotenv import load_dotenv
load_dotenv()

os.environ["LANGCHAIN_TRACING_V2"]="true"
os.environ["LANGCHAIN_API_KEY"]=os.getenv("LANGCHAIN_API_KEY")

# Creaci칩n del modelo. La temperatura indica qu칠 tan preciso debe ser el modelo
llm = Ollama(model="llama3", temperature=0)
chat_history = []

# Definir el prompt template
prompt_template = ChatPromptTemplate.from_messages(
    [
        (
            "system", """Te llamas Kiwi, eres una AI que genera dietas alternativas personalizadas en base a la descripcion de una persona. Adem치s,
            debes contestar a las peticiones acorde al contexto."""
        ),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{input}"),
    ]
)

# Creaci칩n de la cadena que integra el prompt template con el modelo
chain = prompt_template | llm

# Funci칩n para obtener la respuesta del modelo
def get_response(user_input, chat_history):
    response = chain.invoke({"input": user_input, "chat_history": chat_history})
    return response

# Configurar la p치gina
st.set_page_config(page_title="Prueba generaci칩n de Dietas", page_icon="游볭", layout="centered")

# T칤tulo de la aplicaci칩n
st.title("游볭 Chatbot de Dietas Personalizadas")

# Descripci칩n
st.write("춰Bienvenido! Escribe tu mensaje abajo y se te retornar치 una dieta alternativa personalizada.")

# Crear un 치rea de texto para el historial de conversaci칩n
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

# Mostrar el historial de conversaci칩n
for message in st.session_state.chat_history:
    if isinstance(message, HumanMessage):
        with st.chat_message("user"):
            st.markdown(f"T칰: {message.content}")
    else:
        with st.chat_message("assistant"):
            st.markdown(f"Bot: {message.content}")

# Entrada de usuario
user_input = st.chat_input("Tu mensaje:", key="input")

# Bot칩n de env칤o
if user_input:
    # A침adir el mensaje del usuario al historial
    st.session_state.chat_history.append(HumanMessage(content=user_input))

    # Obtener la respuesta del modelo
    response = get_response(user_input, st.session_state.chat_history)

    # A침adir la respuesta del modelo al historial
    st.session_state.chat_history.append(AIMessage(content=response))

    # Limpiar la entrada del usuario
    st.experimental_rerun()

# Footer
st.markdown("<hr>", unsafe_allow_html=True)
st.markdown("Desarrollado por Alan Bedoya")
